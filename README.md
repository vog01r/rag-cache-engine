# RAG Caching Demo

Une dÃ©monstration pÃ©dagogique et reproductible de la mÃ©thodologie **RAG (Retrieval-Augmented Generation)** avec systÃ¨me de cache intelligent.

## ğŸ¯ Objectif

Ce projet illustre comment construire un systÃ¨me RAG complet incluant :
- **Ingestion** de documents avec chunking automatique
- **Vectorisation** via sentence-transformers (local)
- **Recherche vectorielle** avec FAISS (en mÃ©moire)
- **Cache intelligent** avec TTL pour optimiser les performances
- **GÃ©nÃ©ration** de rÃ©ponses (avec adapter LLM mockable)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documents     â”‚â”€â”€â”€â–¶â”‚   Chunking   â”‚â”€â”€â”€â–¶â”‚   Embeddings    â”‚
â”‚  (.md, .txt)    â”‚    â”‚   (tokens)   â”‚    â”‚ (sentence-bert) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Response     â”‚â—€â”€â”€â”€â”‚     LLM      â”‚â—€â”€â”€â”€â”‚  Vector Store     â”‚
â”‚   (avec cache)  â”‚    â”‚  (mockable)  â”‚    â”‚    (FAISS)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²                      â”‚
                              â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚            â”‚    Retrieval      â”‚
                              â”‚            â”‚   (k-NN + filter) â”‚
                              â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                      â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     Query
```

## ğŸš€ DÃ©marrage rapide

### Installation

```bash
# Cloner le dÃ©pÃ´t
git clone <repo-url>
cd rag_caching

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Lancement de la dÃ©mo

```bash
# Script de dÃ©mo complet
python demo.py

# Ou via le script bash
./demo.sh
```

### Tests

```bash
# Lancer tous les tests
pytest tests/

# Tests avec verbositÃ©
pytest -v tests/

# Tests spÃ©cifiques
pytest tests/test_rag_flow.py -v
```

## ğŸ“ Structure du projet

```
rag_cashing/
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ config.yaml                  # Configuration globale
â”œâ”€â”€ demo.py                      # Script de dÃ©monstration
â”œâ”€â”€ demo.sh                      # Script bash de lancement
â”‚
â”œâ”€â”€ src/                         # Code source principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embedder.py              # Interface + sentence-transformers
â”‚   â”œâ”€â”€ vector_store.py          # Wrapper FAISS avec persistance
â”‚   â”œâ”€â”€ retriever.py             # Logique de rÃ©cupÃ©ration k-NN
â”‚   â”œâ”€â”€ rag_engine.py            # Orchestration complÃ¨te + cache
â”‚   â”œâ”€â”€ llm_adapter.py           # Interface LLM + implÃ©mentation mock
â”‚   â””â”€â”€ utils.py                 # Utilitaires (chargement, chunking)
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â””â”€â”€ RAG.md                   # MÃ©thodologie et concepts
â”‚
â”œâ”€â”€ samples/                     # DonnÃ©es d'exemple
â”‚   â””â”€â”€ docs_to_ingest/          # Documents pour dÃ©mo
â”‚       â”œâ”€â”€ introduction_rag.md
â”‚       â”œâ”€â”€ vectorisation.md
â”‚       â””â”€â”€ cache_optimisation.md
â”‚
â”œâ”€â”€ tests/                       # Tests unitaires
â”‚   â”œâ”€â”€ test_embedder.py
â”‚   â”œâ”€â”€ test_vector_store.py
â”‚   â”œâ”€â”€ test_retriever.py
â”‚   â””â”€â”€ test_rag_flow.py
â”‚
â””â”€â”€ archive/                     # Archivage des versions prÃ©cÃ©dentes
    â””â”€â”€ ORIG_20250921_225920/
```

## âš™ï¸ Configuration

Le fichier `config.yaml` permet d'ajuster les paramÃ¨tres :

```yaml
embedding:
  model_name: "all-MiniLM-L6-v2"  # ModÃ¨le sentence-transformers

vector_store:
  dimension: 384                   # Dimension des embeddings

retrieval:
  k: 4                            # Nombre de documents Ã  rÃ©cupÃ©rer

cache:
  ttl_seconds: 3600               # DurÃ©e de vie du cache (1h)
  max_size: 1000                  # Taille max du cache

chunking:
  max_tokens: 500                 # Taille max des chunks
  overlap: 50                     # Chevauchement entre chunks
```

## ğŸ”§ Utilisation du code

### Exemple basique

```python
from src.embedder import SentenceTransformersEmbedder
from src.vector_store import VectorStore
from src.llm_adapter import MockLLM
from src.rag_engine import RAGEngine

# Initialisation
embedder = SentenceTransformersEmbedder()
vector_store = VectorStore(dimension=384)
llm_adapter = MockLLM()

# Moteur RAG
rag = RAGEngine(embedder, vector_store, llm_adapter)

# Ingestion de documents
documents = [
    {"text": "Le RAG combine recherche et gÃ©nÃ©ration...", "source": "doc1.md"},
    {"text": "FAISS est une bibliothÃ¨que de recherche vectorielle...", "source": "doc2.md"}
]
rag.ingest_documents(documents)

# RequÃªte
result = rag.answer("Qu'est-ce que le RAG ?")
print(result['answer'])
```

### Persistance

```python
# Sauvegarde du vector store
vector_store.save("./mon_index")

# Chargement
vector_store.load("./mon_index")
```

### Cache personnalisÃ©

```python
# DÃ©sactiver le cache
rag = RAGEngine(embedder, vector_store, llm_adapter, enable_cache=False)

# Cache avec TTL personnalisÃ©
rag = RAGEngine(embedder, vector_store, llm_adapter, cache_ttl=1800)  # 30min
```

## ğŸ§ª Tests et validation

Les tests couvrent :
- âœ… Embedding de textes
- âœ… Stockage et recherche vectorielle
- âœ… RÃ©cupÃ©ration avec filtrage
- âœ… Cache avec TTL
- âœ… Flux RAG complet

## ğŸ“Š Performances

La dÃ©mo inclut des mÃ©triques de performance :
- Temps de traitement des requÃªtes
- EfficacitÃ© du cache (hits/misses)
- Statistiques du vector store

## ğŸ”® Extensions possibles

Ce projet sert de base pour :

1. **LLM rÃ©els** : Remplacer MockLLM par OpenAI, Anthropic, etc.
2. **Base vectorielle persistante** : Chroma, Pinecone, Weaviate
3. **Recherche hybride** : Combinaison dense + sparse (BM25)
4. **MÃ©tadonnÃ©es avancÃ©es** : Filtrage par date, auteur, type
5. **Interface web** : Streamlit, FastAPI, Gradio
6. **Monitoring** : MÃ©triques, logs, observabilitÃ©

## ğŸ¤ Contribution

Contributions bienvenues ! Veuillez :
1. Forker le projet
2. CrÃ©er une branche feature
3. Ajouter des tests pour les nouvelles fonctionnalitÃ©s
4. Soumettre une pull request

## ğŸ“ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“š Ressources

- [Documentation RAG](docs/RAG.md) - Concepts et mÃ©thodologie
- [Sentence Transformers](https://www.sbert.net/) - ModÃ¨les d'embedding
- [FAISS](https://github.com/facebookresearch/faiss) - Recherche vectorielle
- [Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401) - Article original
